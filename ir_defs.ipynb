{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def append_csv_files()\n",
    "appends all the data files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_csv_files(folder_path, output_file):\n",
    "    combined_df = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for filename in os.listdir(folder_path):  # Iterate through each file in the specified folder\n",
    "        if filename.endswith('.csv'):  # Check if the file has a .csv extension\n",
    "            file_path = os.path.join(folder_path, filename)  # Construct the full file path\n",
    "            df = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "\n",
    "            if combined_df.empty:  # If the combined DataFrame is empty, initialize it with the first DataFrame\n",
    "                combined_df = df\n",
    "            else:\n",
    "                if list(combined_df.columns) == list(df.columns):  # Check if the column names are the same\n",
    "                    combined_df = pd.concat([combined_df, df], ignore_index=True)  # Append the rows\n",
    "\n",
    "    combined_df.to_csv(output_file, index=False) \n",
    "\n",
    "#examples: \n",
    "#folder_path = 'C:\\\\Users\\\\kmh\\\\Documents\\\\DATA\\\\2024-5\\\\RFID'  # Replace with your folder path\n",
    "#output_file = 'RFID_24Dec11_04.csv'\n",
    "#append_csv_files(folder_path, output_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def append_force_text_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_force_text_files(folder_path, output_file):\n",
    "    # Initialize an empty DataFrame\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as f_out:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                df = pd.read_csv(file_path, delimiter=',')  # Read the text file into a DataFrame\n",
    "\n",
    "                if combined_df.empty:\n",
    "                    combined_df = df\n",
    "                    combined_df.to_csv(f_out, index=False, sep=',')  # Write the header and first chunk\n",
    "                else:\n",
    "                    df.to_csv(f_out, index=False, sep=',', header=False)  # Append without writing the header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def convert_time() for force, rfid, and IR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert seconds since 1904-01-01 to datetime format for force data\n",
    "def convert_time_force(seconds):\n",
    "    base_time = datetime(1904, 1, 1)\n",
    "    return (base_time + timedelta(seconds=seconds)).strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n",
    "\n",
    "# Function to convert microseconds since 1970-01-01 to datetime format for rfid data\n",
    "def convert_time_rfid(microseconds):\n",
    "    if pd.isna(microseconds):\n",
    "        return np.nan\n",
    "    base_time = datetime(1970, 1, 1)\n",
    "    return (base_time + timedelta(microseconds=microseconds)).strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n",
    "\n",
    "# Function to convert microseconds since 1970-01-01 to datetime format for IR data\n",
    "def convert_time_IR(milliseconds):\n",
    "    base_time = datetime(1970, 1, 1)\n",
    "    return (base_time + timedelta(milliseconds=milliseconds)).strftime('%Y-%m-%d %H:%M:%S:%f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def find_and_filter_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence to filter\n",
    "\n",
    "# the df should have the following columns and format:\n",
    "\n",
    "#Sensor               int32\n",
    "#Time               float64\n",
    "#datetime    datetime64[ns]\n",
    "\n",
    "sequence = [1, 2, 3, 4, 5]\n",
    "# Function to find and filter the sequence in the 'Sensor' column with possible repeated elements\n",
    "def find_and_filter_sequence(df, seq):\n",
    "    seq_len = len(seq)\n",
    "    filtered_indices = []\n",
    "    takeoff_event = []\n",
    "    event_number = 1\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(df):\n",
    "        if df['Sensor'].iloc[i] == seq[0]:\n",
    "            match = True\n",
    "            seq_index = 0\n",
    "            for j in range(i, len(df)):\n",
    "                if df['Sensor'].iloc[j] == seq[seq_index]:\n",
    "                    seq_index += 1\n",
    "                    if seq_index == seq_len:\n",
    "                        # Include all subsequent repeated elements of the last sequence element\n",
    "                        while j + 1 < len(df) and df['Sensor'].iloc[j + 1] == seq[-1]:\n",
    "                            j += 1\n",
    "                        filtered_indices.extend(range(i, j + 1))\n",
    "                        takeoff_event.extend([event_number] * (j - i + 1))\n",
    "                        event_number += 1\n",
    "                        i = j\n",
    "                        break\n",
    "                elif df['Sensor'].iloc[j] != seq[seq_index - 1]:\n",
    "                    match = False\n",
    "                    break\n",
    "        i += 1\n",
    "    \n",
    "    filtered_df = df.iloc[filtered_indices].copy()\n",
    "    filtered_df['takeoff_event'] = takeoff_event\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# use example\n",
    "#filtered_IR_Sensor = find_and_filter_sequence(IR_unique, sequence)\n",
    "#filtered_IR_Sensor: full dataset with 'Sensor' column filtered\n",
    "\n",
    "# Display the filtered DataFrame A\n",
    "#print(filtered_IR_Sensor.head(10))\n",
    "#print(filtered_IR_Sensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def isolate_takeoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input df should have the following format, as the product of def find_and_filter_sequence()\n",
    "\n",
    "#index                     int64\n",
    "#Sensor                    int32\n",
    "#Time                    float64\n",
    "#datetime         datetime64[ns]\n",
    "#takeoff_event             int64\n",
    "#dtype: object\n",
    "\n",
    "def isolate_takeoff(df):\n",
    "\n",
    "    df = df.drop_duplicates().sort_values(by = 'datetime').reset_index() #drop duplicates that has same timestamp \n",
    "\n",
    "    i = 0\n",
    "    keep_indices = []\n",
    "\n",
    "    while i < len(df) - 1:\n",
    "        first_sensor_reading = df['Sensor'].iloc[i]\n",
    "        \n",
    "        # Always keep the first reading of a new sensor value\n",
    "        if i == 0 or df['Sensor'].iloc[i] != df['Sensor'].iloc[i - 1]:\n",
    "            keep_indices.append(i)\n",
    "        \n",
    "        if df['Sensor'].iloc[i + 1] == first_sensor_reading:\n",
    "            time_diff = (df['datetime'].iloc[i + 1] - df['datetime'].iloc[i]).total_seconds()\n",
    "            \n",
    "            if time_diff < 0.5:\n",
    "                keep_indices.append(i + 1)\n",
    "            else:\n",
    "                # Skip all subsequent rows with the same sensor value\n",
    "                while i < len(df) - 1 and df['Sensor'].iloc[i + 1] == first_sensor_reading:\n",
    "                    i += 1\n",
    "        else:\n",
    "            keep_indices.append(i)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    # Add the last index if it wasn't added\n",
    "    if i == len(df) - 1 and (df['datetime'].iloc[i] - df['datetime'].iloc[i - 1]).total_seconds() < 0.5:\n",
    "        keep_indices.append(i)\n",
    "\n",
    "    # Drop duplicates in keep_indices\n",
    "    keep_indices = list(dict.fromkeys(keep_indices))\n",
    "\n",
    "    return df.iloc[keep_indices]\n",
    "\n",
    "\n",
    "# use example\n",
    "# Apply the function and show the result\n",
    "#final_filtered_df = isolate_takeoff(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def process_row \n",
    "- matching ir and rfid one row at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFID_match should have the following format:\n",
    "#  \n",
    "#id                              object\n",
    "#status                          object\n",
    "#epoch_time_converted    datetime64[ns]\n",
    "#dtype: object\n",
    "#<class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "#takeoff_match should have the following format:\n",
    "# \n",
    "#takeoff_event\tdatetime\tRFID\n",
    "#0\t1\t2024-12-11 08:00:48.289\t<NA>\n",
    "#1\t2\t2024-12-11 08:02:31.780\t<NA>\n",
    "#2\t3\t2024-12-11 08:02:36.599\t<NA>\n",
    "\n",
    "\n",
    "def process_row(i, RFID_match, takeoff_match):\n",
    "    print(f\"Processing row: {i}\")\n",
    "    if RFID_match['status'].iloc[i] == \"Arrive\" and RFID_match['status'].iloc[i + 1] in [\"Displace\", \"Depart\"]:\n",
    "        arrival_time = RFID_match['epoch_time_converted'].iloc[i]\n",
    "        depart_time = RFID_match['epoch_time_converted'].iloc[i + 1]\n",
    "        arrival_RFID = RFID_match['id'].iloc[i]\n",
    "        #print(f\"Arrive found at row {i} with RFID {arrival_RFID} from {arrival_time} to {depart_time}\")\n",
    "\n",
    "        # Vectorized operation to assign RFID\n",
    "        mask = (takeoff_match['datetime'] > arrival_time) & (takeoff_match['datetime'] < depart_time)\n",
    "        takeoff_match.loc[mask, 'RFID'] = arrival_RFID\n",
    "        print(f\"Assigned RFID {arrival_RFID} to {mask.sum()} rows in takeoff_match\")\n",
    "\n",
    "    elif RFID_match['status'].iloc[i] == \"Displace\" and RFID_match['status'].iloc[i + 1] == \"Depart\":\n",
    "        arrival_time = RFID_match['epoch_time_converted'].iloc[i]\n",
    "        depart_time = RFID_match['epoch_time_converted'].iloc[i + 1]\n",
    "        arrival_RFID = RFID_match['id'].iloc[i]\n",
    "        #print(f\"Displace found at row {i} with RFID {arrival_RFID} from {arrival_time} to {depart_time}\")\n",
    "\n",
    "        # Vectorized operation to assign RFID\n",
    "        mask = (takeoff_match['datetime'] > arrival_time) & (takeoff_match['datetime'] < depart_time)\n",
    "        takeoff_match.loc[mask, 'RFID'] = arrival_RFID\n",
    "        print(f\"Assigned RFID {arrival_RFID} to {mask.sum()} rows in takeoff_match\")\n",
    "\n",
    "# Use example: Process rows sequentially\n",
    "#for i in tqdm(range(len(RFID_match) - 1)):\n",
    "#    process_row(i) #just 6.4 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def firstbroken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the input df should be in this format\n",
    "#index              int64\n",
    "#Sensor             int32\n",
    "#Time             float64\n",
    "#datetime          object\n",
    "#takeoff_event      int64\n",
    "#RFID              object\n",
    "#dtype: object\n",
    "\n",
    "#returns results_df with firstbroken sensors in the format of: \n",
    "#RFID\tfirstbroken1\tfirstbroken2\tfirstbroken3\tfirstbroken4\tfirstbroken5\n",
    "#0\t3B0018C6F9\t1.733904e+12\tNaN\tNaN\tNaN\tNaN\n",
    "#1\t<NA>\tNaN\t1.733904e+12\tNaN\tNaN\tNaN\n",
    "#2\t<NA>\tNaN\tNaN\t1.733904e+12\tNaN\tNaN\n",
    "#3\t<NA>\tNaN\tNaN\tNaN\t1.733904e+12\tNaN\n",
    "#4\t<NA>\tNaN\tNaN\tNaN\tNaN\t1.733904e+12\n",
    "\n",
    "\n",
    "def firstbroken(df):\n",
    "    # Initialize the results list\n",
    "    results_list = []\n",
    "    # Initialize start_index\n",
    "    start_index = 0\n",
    "\n",
    "    # Iterate over the DataFrame\n",
    "    for i in range(len(df)):\n",
    "        first_read = df['Time'].iloc[start_index]\n",
    "        current_sensor = df['Sensor'].iloc[start_index]\n",
    "\n",
    "        #rfid assignment\n",
    "        rfid = df['RFID'].iloc[start_index] if current_sensor == 1 else pd.NA\n",
    "\n",
    "        # Debugging print statements \n",
    "        print(f\"Iteration {i}:\")\n",
    "        print(f\"  start_index: {start_index}\")\n",
    "        print(f\"  first_read: {first_read}\")\n",
    "        print(f\"  current_sensor: {current_sensor}\")\n",
    "        print(f\"  rfid: {rfid}\")\n",
    "\n",
    "\n",
    "        for j in range(start_index, len(df)):\n",
    "            if df['Sensor'].iloc[j] != current_sensor:\n",
    "                start_index = j\n",
    "                print(f\"  Sensor changed at index {j}, new start_index: {start_index}\")\n",
    "                break\n",
    "\n",
    "        results_list.append({\n",
    "            f'RFID': rfid,\n",
    "            f'firstbroken{current_sensor}': first_read,\n",
    "        })\n",
    "\n",
    "    # Convert results_list to DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def irfid_allign()\n",
    "- alligns the above results_df without NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irfid_allign(results_df):\n",
    "    # Initialize an empty DataFrame with specified columns\n",
    "    irfid_alligned = pd.DataFrame(columns=['RFID', 'firstbroken1', 'firstbroken2', 'firstbroken3', 'firstbroken4', 'firstbroken5'])\n",
    "\n",
    "    # Iterate through results_df\n",
    "    for i in range(len(results_df) - 4):\n",
    "        if pd.notna(results_df['RFID'].iloc[i]):\n",
    "            rfid = results_df['RFID'].iloc[i]\n",
    "            firstbroken1 = results_df['firstbroken1'].iloc[i]\n",
    "            firstbroken2 = results_df['firstbroken2'].iloc[i+1]\n",
    "            firstbroken3 = results_df['firstbroken3'].iloc[i+2]\n",
    "            firstbroken4 = results_df['firstbroken4'].iloc[i+3]\n",
    "            firstbroken5 = results_df['firstbroken5'].iloc[i+4]\n",
    "            firstbroken_values = [firstbroken1, firstbroken2, firstbroken3, firstbroken4, firstbroken5]\n",
    "\n",
    "            #print(f\"Checking row {i}: RFID={rfid}, firstbroken_values={firstbroken_values}\")\n",
    "\n",
    "            if pd.notna(firstbroken_values).all():\n",
    "                row = [rfid] + firstbroken_values\n",
    "                irfid_alligned.loc[len(irfid_alligned)] = row\n",
    "\n",
    "    print(irfid_alligned)\n",
    "\n",
    "\n",
    "#output dataset: \n",
    "#RFID\tfirstbroken1\tfirstbroken2\tfirstbroken3\tfirstbroken4\tfirstbroken5\n",
    "#0\t3B0018C6F9\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\n",
    "#1\t3B00185E23\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def speed_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the input irfid_new looks like this:\n",
    "#RFID\tfirstbroken1\tfirstbroken2\tfirstbroken3\tfirstbroken4\tfirstbroken5\tdatetime\ttakeoff_event\n",
    "#0\t3B0018C6F9\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t2024-12-11 08:00:48.289\t1\n",
    "#1\t3B00185E23\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t2024-12-11 08:02:36.599\t3\n",
    "#2\t3B00185CB8\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t1.733904e+12\t2024-12-11 08:05:55.755\t6\n",
    "\n",
    "\n",
    "\n",
    "#the output irfid_calc looks like this: \n",
    "#RFID  firstbroken1  firstbroken2  firstbroken3  firstbroken4  \\\n",
    "#0  3B0018C6F9      1.733904      1.733904      1.733904      1.733904   \n",
    "#1  3B00185E23      1.733904      1.733904      1.733904      1.733904   \n",
    "\n",
    "#   firstbroken5                 datetime  takeoff_event           t12  \\\n",
    "#0      1.733904  2024-12-11 08:00:48.289              1  2.830001e-10   \n",
    "#1      1.733904  2024-12-11 08:02:36.599              3  1.340001e-10   \n",
    "\n",
    "#            t23  ...           t45            v1            v2            v3  \\\n",
    "#0  1.310001e-10  ...  6.699996e-11  4.770317e+08  1.030534e+09  2.327593e+09   \n",
    "#1  6.899992e-11  ...  7.399992e-11  1.007462e+09  1.956524e+09  2.288130e+09   \n",
    "\n",
    "#             v4         avg.v          acc1          acc2          acc3  \\\n",
    "#0  2.014927e+09  1.001855e+09  2.673921e+18  1.372550e+19 -5.002674e+18   \n",
    "#1  1.824326e+09  1.607142e+09  9.350367e+18  5.181344e+18 -6.974491e+18   \n",
    "  \n",
    "#        avg.acc  \n",
    "#0 -1.310527e+18  \n",
    "#1 -4.342505e+18  \n",
    "\n",
    "\n",
    "def speed_calculation(irfid_new):\n",
    "    irfid_calc = pd.DataFrame()\n",
    "    irfid_calc = irfid_new\n",
    "    #seconds\n",
    "    irfid_calc['firstbroken1'] = irfid_calc['firstbroken1']/1000\n",
    "    irfid_calc['firstbroken2'] = irfid_calc['firstbroken2']/1000\n",
    "    irfid_calc['firstbroken3'] = irfid_calc['firstbroken3']/1000\n",
    "    irfid_calc['firstbroken4'] = irfid_calc['firstbroken4']/1000\n",
    "    irfid_calc['firstbroken5'] = irfid_calc['firstbroken5']/1000\n",
    "\n",
    "    #time\n",
    "    irfid_calc['t12'] = irfid_calc['firstbroken2'] - irfid_calc['firstbroken1']\n",
    "    irfid_calc['t23'] = irfid_calc['firstbroken3'] - irfid_calc['firstbroken2']\n",
    "    irfid_calc['t34'] = irfid_calc['firstbroken4'] - irfid_calc['firstbroken3']\n",
    "    irfid_calc['t45'] = irfid_calc['firstbroken5'] - irfid_calc['firstbroken4']\n",
    "\n",
    "    #speed\n",
    "    irfid_calc['v1'] = 0.135/irfid_calc['t12']\n",
    "    irfid_calc['v2'] = 0.135/irfid_calc['t23']\n",
    "    irfid_calc['v3'] = 0.135/irfid_calc['t34']\n",
    "    irfid_calc['v4'] = 0.135/irfid_calc['t45']\n",
    "    irfid_calc['avg.v'] = 0.540/(irfid_calc['firstbroken5'] - irfid_calc['firstbroken1'])\n",
    "\n",
    "    #acceleration\n",
    "    irfid_calc['acc1'] = 2*(irfid_calc['v2'] - irfid_calc['v1'])/(irfid_calc['t12'] + irfid_calc['t23'])\n",
    "    irfid_calc['acc2'] = 2*(irfid_calc['v3'] - irfid_calc['v2'])/(irfid_calc['t23'] + irfid_calc['t34'])\n",
    "    irfid_calc['acc3'] = 2*(irfid_calc['v4'] - irfid_calc['v3'])/(irfid_calc['t34'] + irfid_calc['t45'])\n",
    "    irfid_calc['avg.acc'] = irfid_calc['v4'] - irfid_calc['v1']/(irfid_calc['t23']+irfid_calc['t34']+1/2*(irfid_calc['t12']+irfid_calc['t45']))\n",
    "\n",
    "    #filtering\n",
    "    irfid_calc[(irfid_calc['t12'] <0.25 )& (irfid_calc['t23'] <0.25)] #flying bird should exit the section less than quarter of a second.\n",
    "    print(irfid_calc.head(3))\n",
    "    print(irfid_calc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def match_keys_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keys_preparation(F_df, RFID_match):\n",
    "\n",
    "    F_df_uniq_ts = pd.DataFrame()\n",
    "    RFID_match_uniq_ts = pd.DataFrame()\n",
    "\n",
    "    #F_df preparation\n",
    "    F_df_uniq_ts['hr'] = F_df['datetime'].dt.hour\n",
    "    F_df_uniq_ts['min'] = F_df['datetime'].dt.minute\n",
    "    F_df_uniq_ts['s'] = F_df['datetime'].dt.second\n",
    "\n",
    "    #RFID_match preparation\n",
    "    RFID_match_uniq_ts['hr'] = RFID_match['epoch_time_converted'].dt.hour\n",
    "    RFID_match_uniq_ts['min'] = RFID_match['epoch_time_converted'].dt.minute\n",
    "    RFID_match_uniq_ts['s'] = RFID_match['epoch_time_converted'].dt.second\n",
    "    RFID_match_uniq_ts['rfid'] = RFID_match['id']\n",
    "    RFID_match_uniq_ts['status'] = RFID_match['status']\n",
    "\n",
    "    #unique combinations of hr,min, and s \n",
    "    F_match_keys = F_df_uniq_ts[['hr', 'min','s']].drop_duplicates()\n",
    "    RFID_match_keys = RFID_match_uniq_ts[['hr', 'min','s','rfid', 'status']].drop_duplicates()\n",
    "    #print(f'RFID_match_keys: {RFID_match_keys.head(5)}')\n",
    "    # Create a timestamp column from hr, min, s columns\n",
    "    # need to go through the pain of making it a datetime format in case 59 + 1 becomes 00 in seconds\n",
    "\n",
    "    \n",
    "    F_match_keys['timestamp'] = pd.to_datetime(F_match_keys[['hr', 'min', 's']]\n",
    "                                            .astype(str).agg(':'.join, axis=1), format='%H:%M:%S')\n",
    "\n",
    "    RFID_match_keys['timestamp'] = pd.to_datetime(RFID_match_keys[['hr', 'min', 's']]\n",
    "                                            .astype(str).agg(':'.join, axis=1), format='%H:%M:%S')\n",
    "\n",
    "    #print(f'RFID_match_keys in the function: {RFID_match_keys.head(5)}')\n",
    "\n",
    "\n",
    "    # Initialize event counter and event list\n",
    "    event_counter = 1\n",
    "    events = [event_counter]\n",
    "\n",
    "    # Iterate over the rows of the DataFrame to mark the event \n",
    "    # event = a set of consecutive seconds\n",
    "    for i in range(len(F_match_keys) - 1):\n",
    "        if F_match_keys['timestamp'].iloc[i + 1] == F_match_keys['timestamp'].iloc[i] + timedelta(seconds=1):\n",
    "            events.append(event_counter)\n",
    "        else:\n",
    "            event_counter += 1\n",
    "            events.append(event_counter)\n",
    "\n",
    "    # Add the event column to the F_match_keys \n",
    "    F_match_keys['event'] = events\n",
    "    F_match_keys['timestamp'] = F_match_keys['timestamp'].dt.time\n",
    "    RFID_match_keys['timestamp'] = RFID_match_keys['timestamp'].dt.time\n",
    "\n",
    "    # Reset index and make it a column named 'index'\n",
    "    F_match_keys.reset_index(inplace=True)\n",
    "    F_match_keys.rename(columns={'index': 'index'}, inplace=True)\n",
    "    #print(F_match_keys)\n",
    "\n",
    "    #add RFID column as a matchkey\n",
    "    F_match_keys['RFID'] =pd.NA\n",
    "\n",
    "    return F_match_keys, RFID_match_keys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(RFID_match_keys, F_match_keys, F_df, start_index=0):  \n",
    "    current_F_valid = pd.DataFrame()\n",
    "    F_match_keys_in = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(RFID_match_keys) - 1):\n",
    "        if RFID_match_keys.loc[i, 'status'] == \"Arrive\" and RFID_match_keys.loc[i + 1, 'status'] in [\"Displace\", \"Depart\"]:\n",
    "            arrival_time = RFID_match_keys.loc[i, 'timestamp']  \n",
    "            depart_time = RFID_match_keys.loc[i + 1, 'timestamp'] \n",
    "            arrival_RFID = RFID_match_keys.loc[i, 'rfid']\n",
    "\n",
    "            # Adjust the mask to start from start_index\n",
    "            mask = (F_match_keys['timestamp'] >= arrival_time) & (F_match_keys['timestamp'] <= depart_time) & (F_match_keys['index'] >= start_index)\n",
    "                \n",
    "            if not F_match_keys.loc[mask].empty:\n",
    "                matching_event = F_match_keys.loc[mask, 'event'].iloc[0]\n",
    "                matching_start_index = F_match_keys.loc[mask, 'index'].iloc[0]\n",
    "                matching_end_index = F_match_keys.loc[mask, 'index'].iloc[-1]\n",
    "\n",
    "                #directly stores assigns RFID to the raw F_df file in current_F_valid\n",
    "                current_F_valid = F_df.loc[matching_start_index:(matching_end_index+999), :]\n",
    "                current_F_valid['RFID'] = arrival_RFID\n",
    "                current_F_valid['event'] = matching_event\n",
    "\n",
    "                F_match_keys.loc[mask, 'RFID'] = arrival_RFID\n",
    "                F_match_keys_in = F_match_keys[F_match_keys['RFID'].notna()]\n",
    "\n",
    "                return F_match_keys_in, current_F_valid, matching_end_index\n",
    "\n",
    "    return F_match_keys_in, current_F_valid, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
